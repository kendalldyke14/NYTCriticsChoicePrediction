{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with OMDB Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in OMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb2020 = pd.read_csv(\"data/OMDBData2020.csv\")\n",
    "omdb2020.Plot = omdb2020.Plot.fillna(value=\"\")\n",
    "\n",
    "omdb2021 = pd.read_csv(\"data/OMDBData2021.csv\")\n",
    "omdb2021.Plot = omdb2021.Plot.fillna(value=\"\")\n",
    "\n",
    "omdb = omdb2020.append(omdb2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "tfidf_vectorizer_NMF = TfidfVectorizer(max_features = 20000, # only top 5k by freq\n",
    "                                       lowercase = True, # drop capitalization\n",
    "                                       ngram_range = (1,2), # include up to 2-grams, we can make this only 1 if needed\n",
    "                                       min_df=1,  # note: absolute count of doc\n",
    "                                       token_pattern = r'\\b[a-z]{3,12}\\b',   # remove short, non-word-like terms\n",
    "                                       stop_words='english') # default English stopwords\n",
    "\n",
    "tfidf_documents_NMF = tfidf_vectorizer_NMF.fit_transform(omdb[\"Plot\"])\n",
    "feature_names_NMF = tfidf_vectorizer_NMF.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train NMF for n = 2-10 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Topics:\n",
      "[['family', 'young', 'old', 'father', 'year', 'woman', 'year old', 'home', 'mother', 'finds'], ['life', 'new', 'film', 'story', 'world', 'documentary', 'york', 'new york', 'city', 'love']]\n",
      "\n",
      "\n",
      "3 Topics:\n",
      "[['family', 'young', 'old', 'father', 'woman', 'year', 'home', 'year old', 'mother', 'finds'], ['life', 'new', 'film', 'story', 'world', 'documentary', 'york', 'new york', 'city', 'love'], ['school', 'high', 'high school', 'students', 'senior', 'team', 'student', 'school football', 'school students', 'football']]\n",
      "\n",
      "\n",
      "4 Topics:\n",
      "[['family', 'young', 'father', 'woman', 'home', 'mother', 'son', 'wife', 'daughter', 'house'], ['life', 'new', 'film', 'story', 'world', 'documentary', 'york', 'new york', 'love', 'city'], ['school', 'high', 'high school', 'students', 'team', 'senior', 'student', 'school football', 'school students', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'love', 'old daughter', 'girl', 'best', 'friend']]\n",
      "\n",
      "\n",
      "5 Topics:\n",
      "[['family', 'father', 'young', 'woman', 'mother', 'home', 'son', 'wife', 'daughter', 'house'], ['life', 'film', 'story', 'world', 'documentary', 'love', 'american', 'music', 'time', 'people'], ['school', 'high', 'high school', 'students', 'team', 'senior', 'student', 'school football', 'school students', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'love', 'old daughter', 'girl', 'best', 'friend'], ['new', 'york', 'new york', 'city', 'york city', 'right', 'swiped', 'time new', 'swiped right', 'based']]\n",
      "\n",
      "\n",
      "6 Topics:\n",
      "[['family', 'father', 'young', 'woman', 'mother', 'home', 'son', 'wife', 'daughter', 'house'], ['story', 'film', 'world', 'love', 'documentary', 'american', 'time', 'follows', 'people', 'music'], ['school', 'high', 'high school', 'students', 'senior', 'team', 'student', 'school students', 'school football', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'love', 'old daughter', 'girl', 'best', 'friend'], ['new', 'york', 'new york', 'city', 'york city', 'time new', 'swiped', 'swiped right', 'right', 'based'], ['life', 'look', 'work', 'look life', 'life work', 'singer', 'depth look', 'depth', 'songwriter', 'singer songwriter']]\n",
      "\n",
      "\n",
      "7 Topics:\n",
      "[['family', 'father', 'young', 'woman', 'mother', 'home', 'son', 'wife', 'house', 'daughter'], ['world', 'film', 'story', 'documentary', 'american', 'time', 'follows', 'history', 'music', 'people'], ['school', 'high', 'high school', 'students', 'senior', 'team', 'student', 'school students', 'school football', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'old daughter', 'girl', 'best', 'friend', 'thousand year'], ['new', 'york', 'new york', 'city', 'york city', 'swiped right', 'time new', 'swiped', 'right', 'based'], ['life', 'look', 'work', 'look life', 'life work', 'singer', 'depth', 'depth look', 'songwriter', 'singer songwriter'], ['love', 'films', 'short films', 'oscar nominated', 'oscar', 'nominated', 'short', 'nominated short', 'sister', 'animation']]\n",
      "\n",
      "\n",
      "8 Topics:\n",
      "[['family', 'father', 'young', 'mother', 'woman', 'home', 'son', 'wife', 'daughter', 'house'], ['world', 'film', 'story', 'documentary', 'american', 'time', 'music', 'follows', 'history', 'lives'], ['school', 'high', 'high school', 'students', 'senior', 'team', 'school students', 'student', 'school football', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'old daughter', 'girl', 'best', 'friend', 'thousand year'], ['new', 'york', 'new york', 'city', 'york city', 'swiped right', 'swiped', 'time new', 'right', 'based'], ['life', 'look', 'work', 'look life', 'life work', 'singer', 'depth', 'depth look', 'songwriter', 'singer songwriter'], ['love', 'films', 'short films', 'oscar nominated', 'oscar', 'nominated', 'short', 'nominated short', 'sister', 'animation'], ['town', 'small', 'small town', 'local', 'midwest', 'midwest town', 'moves', 'death', 'community', 'terrorizing']]\n",
      "\n",
      "\n",
      "9 Topics:\n",
      "[['world', 'town', 'fight', 'small', 'way', 'finds', 'mysterious', 'group', 'time', 'local'], ['film', 'story', 'documentary', 'american', 'music', 'history', 'black', 'people', 'follows', 'world'], ['school', 'high', 'high school', 'students', 'senior', 'team', 'school students', 'school football', 'student', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'old daughter', 'girl', 'thousand year', 'thousand', 'love'], ['new', 'york', 'new york', 'city', 'york city', 'time new', 'swiped', 'swiped right', 'right', 'based'], ['life', 'look', 'work', 'look life', 'life work', 'depth', 'depth look', 'singer', 'songwriter', 'singer songwriter'], ['love', 'short films', 'oscar nominated', 'films', 'oscar', 'nominated', 'short', 'nominated short', 'sister', 'animation'], ['family', 'home', 'brother', 'new', 'forced', 'trip', 'road', 'mother', 'takes', 'house'], ['young', 'father', 'woman', 'son', 'young woman', 'mother', 'wife', 'daughter', 'girl', 'house']]\n",
      "\n",
      "\n",
      "10 Topics:\n",
      "[['world', 'fight', 'way', 'war', 'time', 'finds', 'mysterious', 'group', 'lives', 'battle'], ['film', 'story', 'documentary', 'american', 'music', 'history', 'black', 'people', 'feature', 'follows'], ['school', 'high school', 'high', 'students', 'senior', 'team', 'school students', 'school football', 'student', 'football'], ['year', 'old', 'year old', 'old girl', 'finds', 'old daughter', 'girl', 'thousand year', 'thousand', 'ground'], ['new', 'york', 'new york', 'city', 'york city', 'swiped', 'swiped right', 'time new', 'right', 'based'], ['life', 'look', 'work', 'look life', 'life work', 'depth', 'depth look', 'singer', 'songwriter', 'singer songwriter'], ['love', 'short films', 'oscar nominated', 'films', 'oscar', 'nominated', 'short', 'nominated short', 'sister', 'animation'], ['family', 'home', 'brother', 'new', 'forced', 'trip', 'road', 'mother', 'takes', 'house'], ['young', 'father', 'woman', 'son', 'young woman', 'mother', 'daughter', 'wife', 'girl', 'house'], ['town', 'small', 'small town', 'midwest', 'local', 'midwest town', 'moves', 'community', 'terrorizing', 'home']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "for num_topics in range(2, 11):\n",
    "    nmf = NMF(\n",
    "        n_components=num_topics,\n",
    "        init='nndsvd', \n",
    "        random_state = 42\n",
    "        )\n",
    "    W = nmf.fit_transform(tfidf_documents_NMF)\n",
    "    H = nmf.components_\n",
    "    top_components = np.argsort(-H)[:, :10]\n",
    "    \n",
    "    topics = []\n",
    "    for t in top_components:\n",
    "        topic_words = []\n",
    "        for w in t:\n",
    "            topic_words.append(feature_names_NMF[w])\n",
    "        topics.append(topic_words)\n",
    "        \n",
    "    print(f\"{num_topics} Topics:\")\n",
    "    print(topics)\n",
    "    print(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYT Full Review Text\n",
    "\n",
    "TFIDF and NMF on full NYT Review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTReviews = pd.read_csv(\"data/NYTData_wReviewText.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_NMF = TfidfVectorizer(max_features = 20000, # only top 5k by freq\n",
    "                                       lowercase = True, # drop capitalization\n",
    "                                       ngram_range = (1,2), # include up to 2-grams, we can make this only 1 if needed\n",
    "                                       min_df=1,  # note: absolute count of doc\n",
    "                                       token_pattern = r'\\b[a-z]{3,12}\\b',   # remove short, non-word-like terms\n",
    "                                       stop_words='english') # default English stopwords\n",
    "\n",
    "tfidf_documents_NMF = tfidf_vectorizer_NMF.fit_transform(NYTReviews[\"review_text\"])\n",
    "feature_names_NMF = tfidf_vectorizer_NMF.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Topics:\n",
      "[['movie', 'like', 'story', 'film', 'character', 'time', 'characters', 'family', 'man', 'life'], ['documentary', 'film', 'says', 'footage', 'new', 'people', 'interviews', 'work', 'black', 'world']]\n",
      "\n",
      "\n",
      "3 Topics:\n",
      "[['movie', 'like', 'story', 'film', 'character', 'time', 'characters', 'family', 'man', 'life'], ['documentary', 'film', 'says', 'footage', 'people', 'new', 'interviews', 'black', 'work', 'history'], ['oscar', 'oscar nominated', 'nominated', 'live action', 'short', 'colette', 'program', 'program hour', 'hour program', 'action']]\n",
      "\n",
      "\n",
      "4 Topics:\n",
      "[['movie', 'like', 'story', 'character', 'characters', 'film', 'time', 'family', 'man', 'woman'], ['film', 'documentary', 'says', 'people', 'camera', 'history', 'subjects', 'world', 'women', 'interviews'], ['oscar', 'oscar nominated', 'nominated', 'live action', 'short', 'colette', 'program', 'hour program', 'program hour', 'action'], ['music', 'new', 'rock', 'york', 'new york', 'musical', 'artist', 'band', 'movie', 'documentary']]\n",
      "\n",
      "\n",
      "5 Topics:\n",
      "[['movie', 'woman', 'women', 'film', 'like', 'man', 'story', 'men', 'horror', 'young'], ['documentary', 'film', 'says', 'footage', 'interviews', 'people', 'new', 'history', 'american', 'black'], ['oscar', 'oscar nominated', 'nominated', 'colette', 'live action', 'short', 'program', 'program hour', 'hour program', 'hour'], ['movie', 'like', 'movies', 'time', 'comedy', 'just', 'played', 'character', 'good', 'directed'], ['family', 'father', 'children', 'mother', 'film', 'school', 'child', 'home', 'son', 'parents']]\n",
      "\n",
      "\n",
      "6 Topics:\n",
      "[['movie', 'like', 'movies', 'character', 'time', 'story', 'just', 'played', 'good', 'comedy'], ['documentary', 'film', 'says', 'people', 'history', 'states', 'united', 'interviews', 'subjects', 'footage'], ['colette', 'oscar', 'oscar nominated', 'nominated', 'burrow', 'bowers', 'latasha', 'year oscar', 'short', 'short films'], ['music', 'new', 'rock', 'artist', 'band', 'musical', 'film', 'york', 'new york', 'documentary'], ['film', 'family', 'mother', 'father', 'home', 'life', 'story', 'movie', 'children', 'woman'], ['program hour', 'hour program', 'hour', 'live action', 'program', 'english', 'live', 'action', 'oscar', 'oscar nominated']]\n",
      "\n",
      "\n",
      "7 Topics:\n",
      "[['movie', 'woman', 'women', 'film', 'like', 'man', 'story', 'men', 'young', 'horror'], ['documentary', 'film', 'says', 'footage', 'interviews', 'people', 'new', 'history', 'american', 'black'], ['colette', 'oscar', 'oscar nominated', 'nominated', 'burrow', 'bowers', 'latasha', 'year oscar', 'short', 'short films'], ['movie', 'like', 'played', 'time', 'character', 'comedy', 'just', 'good', 'directed', 'movies'], ['family', 'father', 'mother', 'film', 'children', 'school', 'home', 'child', 'son', 'parents'], ['deena', 'shadyside', 'fear street', 'trilogy', 'fear', 'sarah', 'street', 'janiak', 'movies', 'summer'], ['program hour', 'hour program', 'hour', 'live action', 'program', 'english', 'live', 'action', 'oscar', 'oscar nominated']]\n",
      "\n",
      "\n",
      "8 Topics:\n",
      "[['woman', 'women', 'movie', 'film', 'like', 'man', 'story', 'men', 'horror', 'world'], ['documentary', 'film', 'says', 'footage', 'interviews', 'people', 'new', 'history', 'american', 'music'], ['colette', 'oscar', 'oscar nominated', 'nominated', 'latasha', 'bowers', 'burrow', 'year oscar', 'short', 'short films'], ['movie', 'like', 'played', 'character', 'comedy', 'time', 'just', 'good', 'directed', 'movies'], ['family', 'father', 'mother', 'home', 'children', 'son', 'child', 'film', 'life', 'drama'], ['school', 'high', 'high school', 'students', 'boys', 'kids', 'girls', 'film', 'student', 'girl'], ['program hour', 'hour program', 'hour', 'live action', 'program', 'english', 'live', 'action', 'oscar', 'oscar nominated'], ['deena', 'fear street', 'shadyside', 'trilogy', 'fear', 'sarah', 'street', 'janiak', 'movies', 'summer']]\n",
      "\n",
      "\n",
      "9 Topics:\n",
      "[['film', 'family', 'mother', 'father', 'home', 'life', 'movie', 'son', 'child', 'man'], ['documentary', 'film', 'says', 'people', 'history', 'footage', 'states', 'united', 'interviews', 'war'], ['colette', 'oscar', 'oscar nominated', 'nominated', 'burrow', 'latasha', 'bowers', 'year oscar', 'short', 'short films'], ['movie', 'like', 'character', 'movies', 'played', 'time', 'good', 'just', 'way', 'story'], ['music', 'rock', 'band', 'new', 'musical', 'singer', 'artist', 'documentary', 'songs', 'film'], ['school', 'high', 'high school', 'students', 'kids', 'boys', 'girls', 'film', 'children', 'student'], ['hour program', 'program hour', 'hour', 'live action', 'program', 'english', 'live', 'action', 'oscar nominated', 'oscar'], ['deena', 'fear street', 'shadyside', 'trilogy', 'fear', 'sarah', 'street', 'janiak', 'movies', 'summer'], ['women', 'men', 'woman', 'black', 'female', 'story', 'like', 'male', 'girls', 'white']]\n",
      "\n",
      "\n",
      "10 Topics:\n",
      "[['film', 'family', 'mother', 'father', 'life', 'home', 'movie', 'man', 'son', 'child'], ['documentary', 'film', 'says', 'people', 'history', 'footage', 'states', 'united', 'interviews', 'war'], ['colette', 'oscar', 'oscar nominated', 'nominated', 'burrow', 'latasha', 'bowers', 'year oscar', 'short', 'short films'], ['movie', 'like', 'character', 'movies', 'played', 'time', 'good', 'just', 'way', 'story'], ['music', 'rock', 'band', 'musical', 'singer', 'new', 'artist', 'documentary', 'songs', 'film'], ['school', 'high', 'high school', 'kids', 'students', 'boys', 'girls', 'film', 'children', 'student'], ['hour program', 'program hour', 'hour', 'live action', 'program', 'english', 'live', 'action', 'oscar nominated', 'oscar'], ['deena', 'shadyside', 'fear street', 'trilogy', 'fear', 'sarah', 'street', 'janiak', 'movies', 'summer'], ['women', 'men', 'woman', 'black', 'female', 'story', 'like', 'male', 'girls', 'husband'], ['frank', 'philip', 'uncle frank', 'mangrove', 'uncle', 'beth', 'new york', 'york', 'hoffa', 'daphne']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "for num_topics in range(2, 11):\n",
    "    nmf = NMF(\n",
    "        n_components=num_topics,\n",
    "        init='nndsvd', \n",
    "        random_state = 42\n",
    "        )\n",
    "    W = nmf.fit_transform(tfidf_documents_NMF)\n",
    "    H = nmf.components_\n",
    "    top_components = np.argsort(-H)[:, :10]\n",
    "    \n",
    "    topics = []\n",
    "    for t in top_components:\n",
    "        topic_words = []\n",
    "        for w in t:\n",
    "            topic_words.append(feature_names_NMF[w])\n",
    "        topics.append(topic_words)\n",
    "        \n",
    "    print(f\"{num_topics} Topics:\")\n",
    "    print(topics)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Topics into Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kenda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# lemmatize the text fields\n",
    "def lemmatize(text_data): \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    lemmas = text_data.apply(lambda w: [lemmatizer.lemmatize(word) for word in re.split('\\s+|-', w.lower())])\n",
    "    return lemmas.apply(lambda s: \" \".join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a tfidf bag of words vectorizer\n",
    "def tfidf_vecorization(data, ngram_range):\n",
    "    tfidf_vectorizer_NMF = TfidfVectorizer(max_features = 20000, # only top 20k by freq\n",
    "                                       lowercase = True, # drop capitalization\n",
    "                                       ngram_range = ngram_range, # include up to n-grams\n",
    "                                       min_df=1,  # note: absolute count of doc\n",
    "                                       token_pattern = r'\\b[a-z]{3,}\\b',   # remove short, non-word-like terms\n",
    "                                       stop_words='english') # default English stopwords\n",
    "\n",
    "    tfidf_documents_NMF = tfidf_vectorizer_NMF.fit_transform(data)\n",
    "    feature_names_NMF = tfidf_vectorizer_NMF.get_feature_names_out()\n",
    "    \n",
    "    return tfidf_documents_NMF, feature_names_NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take TFIDF transformed data and train NMF\n",
    "def trainNMF(tfidf, n_components):\n",
    "    nmf = NMF(\n",
    "        n_components=n_components,\n",
    "        init='nndsvd', \n",
    "        random_state = 42\n",
    "        )\n",
    "    W = nmf.fit_transform(tfidf_documents_NMF)\n",
    "    H = nmf.components_\n",
    "    top_components = np.argsort(-H)[:, :10]\n",
    "\n",
    "    topics = []\n",
    "    for t in top_components:\n",
    "        topic_words = []\n",
    "        for w in t:\n",
    "            topic_words.append(feature_names_NMF[w])\n",
    "        topics.append(topic_words)\n",
    "        \n",
    "    return W, H, topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(\"data/joined_df.csv\")\n",
    "movie_data.Plot = movie_data.Plot.fillna(value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data2 = movie_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign each movie a review topic\n",
    "\n",
    "Using the W matrix, we can see which topic is most related to that movie's review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data['review_text'] = lemmatize(movie_data['review_text'])\n",
    "tfidf_documents_NMF, feature_names_NMF = tfidf_vecorization(movie_data['review_text'], (1,1))\n",
    "W, H, topics = trainNMF(tfidf_documents_NMF, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W is the topic matrix, the highest value within each row will determine the most relevant topic\n",
    "movie_data[\"review_topic\"] = [x.argmax() for x in W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_df = pd.DataFrame(W, columns = [f\"reviewTopic{x}\" for x in range(W.shape[1])])\n",
    "\n",
    "movie_data2 = pd.DataFrame(\n",
    "    np.column_stack([movie_data2,W_df]),\n",
    "    columns=movie_data2.columns.append(W_df.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign each movie a plot topic\n",
    "\n",
    "Using the W matrix, we can see which topic is most related to that movie's plot. (Plot topics are different than review topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_data['Plot'] = stemmer(movie_data['Plot'])\n",
    "movie_data['Plot'] = lemmatize(movie_data['Plot'])\n",
    "tfidf_documents_NMF, feature_names_NMF = tfidf_vecorization(movie_data['Plot'], (1,2))\n",
    "W, H, topics = trainNMF(tfidf_documents_NMF, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W is the topic matrix, the highest value within each row will determine the most relevant topic\n",
    "movie_data[\"plot_topic\"] = [x.argmax() for x in W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_df = pd.DataFrame(W, columns = [f\"plotTopic{x}\" for x in range(W.shape[1])])\n",
    "\n",
    "movie_data2 = pd.DataFrame(\n",
    "    np.column_stack([movie_data2,W_df]),\n",
    "    columns=movie_data2.columns.append(W_df.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1\n",
    "`movie_data` has 2 additional columns, each which show which topic is most closely related to the movie for full reviews and full plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rated</th>\n",
       "      <th>review_topic</th>\n",
       "      <th>plot_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tenet</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dune</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zack Snyder's Justice League</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soul</td>\n",
       "      <td>PG</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soul</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Gentlemen</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Black Widow</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Suicide Squad</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shang-Chi and the Legend of the Ten Rings</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wonder Woman 1984</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  Rated  review_topic  plot_topic\n",
       "0                                      Tenet  PG-13             0           1\n",
       "1                                       Dune  PG-13             0           1\n",
       "2               Zack Snyder's Justice League      R             0           0\n",
       "3                                       Soul     PG             4           2\n",
       "4                                       Soul     PG             0           2\n",
       "5                              The Gentlemen      R             0           1\n",
       "6                                Black Widow  PG-13             0           0\n",
       "7                          The Suicide Squad      R             0           4\n",
       "8  Shang-Chi and the Legend of the Ten Rings  PG-13             0           0\n",
       "9                          Wonder Woman 1984  PG-13             0           0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data[[\"Title\", \"Rated\", \"review_topic\", \"plot_topic\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.to_csv(\"data/movie_data_withTopicAssignment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2\n",
    "`movie_data2` has columns based on **how** close each movie is to a given topic. The higher the value, the more related the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rated</th>\n",
       "      <th>reviewTopic0</th>\n",
       "      <th>reviewTopic1</th>\n",
       "      <th>reviewTopic2</th>\n",
       "      <th>reviewTopic3</th>\n",
       "      <th>reviewTopic4</th>\n",
       "      <th>plotTopic0</th>\n",
       "      <th>plotTopic1</th>\n",
       "      <th>plotTopic2</th>\n",
       "      <th>plotTopic3</th>\n",
       "      <th>plotTopic4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tenet</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0.078854</td>\n",
       "      <td>0.034304</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.004514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dune</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0.113677</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.060843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zack Snyder's Justice League</td>\n",
       "      <td>R</td>\n",
       "      <td>0.106864</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042167</td>\n",
       "      <td>0.020683</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soul</td>\n",
       "      <td>PG</td>\n",
       "      <td>0.071453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037547</td>\n",
       "      <td>0.106921</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.023958</td>\n",
       "      <td>0.089829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soul</td>\n",
       "      <td>PG</td>\n",
       "      <td>0.052249</td>\n",
       "      <td>0.00754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.023958</td>\n",
       "      <td>0.089829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Gentlemen</td>\n",
       "      <td>R</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Black Widow</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0.085369</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030991</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Suicide Squad</td>\n",
       "      <td>R</td>\n",
       "      <td>0.084595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>0.023732</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>0.022882</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>0.049487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shang-Chi and the Legend of the Ten Rings</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0.057941</td>\n",
       "      <td>0.015451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.012717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wonder Woman 1984</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0.128635</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  Rated reviewTopic0 reviewTopic1  \\\n",
       "0                                      Tenet  PG-13     0.078854     0.034304   \n",
       "1                                       Dune  PG-13     0.113677     0.009237   \n",
       "2               Zack Snyder's Justice League      R     0.106864     0.016664   \n",
       "3                                       Soul     PG     0.071453          0.0   \n",
       "4                                       Soul     PG     0.052249      0.00754   \n",
       "5                              The Gentlemen      R     0.082745          0.0   \n",
       "6                                Black Widow  PG-13     0.085369     0.037605   \n",
       "7                          The Suicide Squad      R     0.084595          0.0   \n",
       "8  Shang-Chi and the Legend of the Ten Rings  PG-13     0.057941     0.015451   \n",
       "9                          Wonder Woman 1984  PG-13     0.128635     0.000305   \n",
       "\n",
       "  reviewTopic2 reviewTopic3 reviewTopic4 plotTopic0 plotTopic1 plotTopic2  \\\n",
       "0     0.007126     0.023031          0.0   0.022933   0.062822        0.0   \n",
       "1     0.002602      0.00293     0.000837   0.041164   0.060843        0.0   \n",
       "2       0.0146          0.0          0.0   0.042167   0.020683   0.005755   \n",
       "3          0.0     0.037547     0.106921   0.022669   0.023958   0.089829   \n",
       "4          0.0     0.019459          0.0   0.022669   0.023958   0.089829   \n",
       "5          0.0          0.0     0.013513   0.005333   0.051822   0.002413   \n",
       "6          0.0          0.0          0.0   0.030991   0.020254   0.000916   \n",
       "7          0.0          0.0     0.022584   0.023732   0.029311   0.022882   \n",
       "8          0.0     0.006728     0.012942   0.023629   0.008034   0.004488   \n",
       "9          0.0          0.0     0.001748   0.038651   0.012374        0.0   \n",
       "\n",
       "  plotTopic3 plotTopic4  \n",
       "0   0.006185   0.004514  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "5        0.0   0.000505  \n",
       "6   0.002431   0.002468  \n",
       "7   0.020559   0.049487  \n",
       "8   0.002518   0.012717  \n",
       "9   0.027426        0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data2[[\"Title\", \"Rated\",'reviewTopic0',\n",
    "                 'reviewTopic1', 'reviewTopic2', 'reviewTopic3', 'reviewTopic4', \n",
    "                'plotTopic0', 'plotTopic1', 'plotTopic2', 'plotTopic3', 'plotTopic4']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data2.to_csv(\"data/movie_data_withTopicRelatedness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
