{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from TopicModeling_SupportFunctions import get_texts_and_corpus,lda_gridsearch,get_top_distinct_words_per_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Review Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTReviews = pd.read_csv(\"data/NYTData_wReviewText.csv\")\n",
    "NYTReviews.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "review_text=NYTReviews[[\"review_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed tutorial at this link:\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Hyperparameter Tuning For Highest Coherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a long time to run (5hrs) on last try on my machine:\n",
    "grid_search_params={\n",
    "    'validation_set_corpus_pct':[0.75,1],\n",
    "    'topics_range':[8,10,12,14],\n",
    "    'alpha':[\"symmetric\",\"asymmetric\"],\n",
    "    'eta':[\"symmetric\",\"auto\",None],\n",
    "    'minimum_probability':[0.001,0.01,0.1],\n",
    "    'bigram_min_count':[3,5,7]\n",
    "    }\n",
    "\n",
    "model_results=lda_gridsearch(review_text,grid_search_params)\n",
    "model_results.to_csv(\"lda_model_outputs/lda_tuning_results_01.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results=pd.read_csv(\"lda_model_outputs/lda_tuning_results_01.csv\")\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build LDA Model with Parameters That Produced the Highest Coherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Best Parameters from Grid Search:\n",
    "best_params=model_results[model_results[\"coherence\"]==model_results[\"coherence\"].max()]\n",
    "best_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model using the best results:\n",
    "corpus,id2word,texts = get_texts_and_corpus(review_text,bigram_min_count=best_params[\"topics_range\"].values[0])\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=best_params[\"topics_range\"].values[0], \n",
    "                                        random_state=42,\n",
    "                                        chunksize=100,\n",
    "                                        passes=10,\n",
    "                                        alpha=best_params[\"alpha\"].values[0],\n",
    "                                        eta=best_params[\"eta\"].values[0],\n",
    "                                        minimum_probability=best_params[\"minimum_probability\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Top Distinct Words within Each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Top Distinct Topics b/w selected topics:\n",
    "top_distinct_words_per_topic=get_top_distinct_words_per_topic(lda_model,num_words_to_show=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_distinct_words_per_topic_df = pd.DataFrame(top_distinct_words_per_topic)\n",
    "top_distinct_words_per_topic_df = top_distinct_words_per_topic_df.transpose()\n",
    "top_distinct_words_per_topic_df.columns = [f'Topic   #{x}' for x in np.arange(1,len(top_distinct_words_per_topic)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_distinct_words_per_topic_df.to_csv(\"lda_model_outputs/top10_words_per_LDA_topic.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Top Topics For Each Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = lda_model.get_document_topics(lda_model[corpus], minimum_probability=0.0)\n",
    "all_topics_csr = gensim.matutils.corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "all_topics_df.columns = [f'Topic   #{x}' for x in np.arange(1,len(top_distinct_words_per_topic)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic   #1</th>\n",
       "      <th>Topic   #2</th>\n",
       "      <th>Topic   #3</th>\n",
       "      <th>Topic   #4</th>\n",
       "      <th>Topic   #5</th>\n",
       "      <th>Topic   #6</th>\n",
       "      <th>Topic   #7</th>\n",
       "      <th>Topic   #8</th>\n",
       "      <th>Topic   #9</th>\n",
       "      <th>Topic   #10</th>\n",
       "      <th>Topic   #11</th>\n",
       "      <th>Topic   #12</th>\n",
       "      <th>Topic   #13</th>\n",
       "      <th>Topic   #14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.081347</td>\n",
       "      <td>0.063319</td>\n",
       "      <td>0.550680</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.034330</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.017925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.081795</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>0.052709</td>\n",
       "      <td>0.044891</td>\n",
       "      <td>0.039092</td>\n",
       "      <td>0.529063</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>0.025775</td>\n",
       "      <td>0.023752</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.020529</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.081019</td>\n",
       "      <td>0.561970</td>\n",
       "      <td>0.052306</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.038772</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>0.030811</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.017928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>0.288821</td>\n",
       "      <td>0.063872</td>\n",
       "      <td>0.052502</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>0.038902</td>\n",
       "      <td>0.323527</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.021915</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.579746</td>\n",
       "      <td>0.063455</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.038749</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.017917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic   #1  Topic   #2  Topic   #3  Topic   #4  Topic   #5  Topic   #6  \\\n",
       "562     0.081347    0.063319    0.550680    0.044518    0.038765    0.034330   \n",
       "679     0.081795    0.063827    0.052709    0.044891    0.039092    0.529063   \n",
       "312     0.081019    0.561970    0.052306    0.044527    0.038772    0.034336   \n",
       "1550    0.288821    0.063872    0.052502    0.044680    0.038902    0.323527   \n",
       "622     0.579746    0.063455    0.052278    0.044504    0.038749    0.034314   \n",
       "\n",
       "      Topic   #7  Topic   #8  Topic   #9  Topic   #10  Topic   #11  \\\n",
       "562     0.030806    0.027938    0.025559     0.023553     0.021839   \n",
       "679     0.031066    0.028174    0.025775     0.023752     0.022023   \n",
       "312     0.030811    0.027943    0.025563     0.023557     0.021842   \n",
       "1550    0.030914    0.028036    0.025648     0.023635     0.021915   \n",
       "622     0.030792    0.027925    0.025547     0.023542     0.021829   \n",
       "\n",
       "      Topic   #12  Topic   #13  Topic   #14  \n",
       "562      0.020357     0.019064     0.017925  \n",
       "679      0.020529     0.019225     0.018077  \n",
       "312      0.020361     0.019067     0.017928  \n",
       "1550     0.020429     0.019131     0.017988  \n",
       "622      0.020348     0.019055     0.017917  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTReviews.join(all_topics_df,how=\"left\").to_csv(\"lda_model_outputs/NYT_Reviews_w_TopicRelatedness.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0d4e572fc01779b683641842e5699b5364ec3fd8789377319514354924fc870"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('SIADS694': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
