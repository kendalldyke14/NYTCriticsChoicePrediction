{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from TopicModeling_SupportFunctions import get_texts_and_corpus,lda_gridsearch,get_top_distinct_words_per_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Review Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTReviews = pd.read_csv(\"data/NYTData_wReviewText.csv\")\n",
    "NYTReviews.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "review_text=NYTReviews[[\"review_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for use of gensim library:\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Hyperparameter Tuning For Highest Coherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a long time to run (5hrs) on last try on my machine:\n",
    "grid_search_params={\n",
    "    'validation_set_corpus_pct':[0.75,1],\n",
    "    'topics_range':[8,10,12,14],\n",
    "    'alpha':[\"symmetric\",\"asymmetric\"],\n",
    "    'eta':[\"symmetric\",\"auto\",None],\n",
    "    'minimum_probability':[0.001,0.01,0.1],\n",
    "    'bigram_min_count':[3,5,7]\n",
    "    }\n",
    "\n",
    "model_results=lda_gridsearch(review_text,grid_search_params)\n",
    "model_results.to_csv(\"lda_model_outputs/lda_tuning_results_01.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_set_corpus_pct</th>\n",
       "      <th>topics_range</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>minimum_probability</th>\n",
       "      <th>bigram_min_count</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.240787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.241541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.241101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.239596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.239209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   validation_set_corpus_pct  topics_range      alpha        eta  \\\n",
       "0                       0.75             8  symmetric  symmetric   \n",
       "1                       0.75             8  symmetric  symmetric   \n",
       "2                       0.75             8  symmetric  symmetric   \n",
       "3                       0.75             8  symmetric       auto   \n",
       "4                       0.75             8  symmetric       auto   \n",
       "\n",
       "   minimum_probability  bigram_min_count  coherence  \n",
       "0                0.001                 3   0.240787  \n",
       "1                0.010                 3   0.241541  \n",
       "2                0.100                 3   0.241101  \n",
       "3                0.001                 3   0.239596  \n",
       "4                0.010                 3   0.239209  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results=pd.read_csv(\"lda_model_outputs/lda_tuning_results_01.csv\")\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build LDA Model with Parameters That Produced the Highest Coherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_set_corpus_pct</th>\n",
       "      <th>topics_range</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>minimum_probability</th>\n",
       "      <th>bigram_min_count</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.75</td>\n",
       "      <td>14</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.267368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     validation_set_corpus_pct  topics_range       alpha        eta  \\\n",
       "353                       0.75            14  asymmetric  symmetric   \n",
       "\n",
       "     minimum_probability  bigram_min_count  coherence  \n",
       "353                  0.1                 7   0.267368  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Best Parameters from Grid Search:\n",
    "best_params=model_results[model_results[\"coherence\"]==model_results[\"coherence\"].max()]\n",
    "best_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model using the best results:\n",
    "corpus,id2word,texts = get_texts_and_corpus(review_text,bigram_min_count=best_params[\"topics_range\"].values[0])\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=best_params[\"topics_range\"].values[0], \n",
    "                                        random_state=42,\n",
    "                                        chunksize=100,\n",
    "                                        passes=10,\n",
    "                                        alpha=best_params[\"alpha\"].values[0],\n",
    "                                        eta=best_params[\"eta\"].values[0],\n",
    "                                        minimum_probability=best_params[\"minimum_probability\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Top Distinct Words within Each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Top Distinct Topics b/w selected topics:\n",
    "top_distinct_words_per_topic=get_top_distinct_words_per_topic(lda_model,num_words_to_show=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic   #1</th>\n",
       "      <th>Topic   #2</th>\n",
       "      <th>Topic   #3</th>\n",
       "      <th>Topic   #4</th>\n",
       "      <th>Topic   #5</th>\n",
       "      <th>Topic   #6</th>\n",
       "      <th>Topic   #7</th>\n",
       "      <th>Topic   #8</th>\n",
       "      <th>Topic   #9</th>\n",
       "      <th>Topic   #10</th>\n",
       "      <th>Topic   #11</th>\n",
       "      <th>Topic   #12</th>\n",
       "      <th>Topic   #13</th>\n",
       "      <th>Topic   #14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danger</td>\n",
       "      <td>grace</td>\n",
       "      <td>claire</td>\n",
       "      <td>ray</td>\n",
       "      <td>exist</td>\n",
       "      <td>disney</td>\n",
       "      <td>wake</td>\n",
       "      <td>luce</td>\n",
       "      <td>lionel</td>\n",
       "      <td>joy</td>\n",
       "      <td>simone</td>\n",
       "      <td>sean</td>\n",
       "      <td>salvador</td>\n",
       "      <td>shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refugee</td>\n",
       "      <td>russian</td>\n",
       "      <td>creature</td>\n",
       "      <td>third</td>\n",
       "      <td>landscape</td>\n",
       "      <td>franchise</td>\n",
       "      <td>network</td>\n",
       "      <td>tesla</td>\n",
       "      <td>shult</td>\n",
       "      <td>classic</td>\n",
       "      <td>garrone</td>\n",
       "      <td>ernesto</td>\n",
       "      <td>almodovar</td>\n",
       "      <td>godzilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complex</td>\n",
       "      <td>energy</td>\n",
       "      <td>dragon</td>\n",
       "      <td>emily</td>\n",
       "      <td>production</td>\n",
       "      <td>exactly</td>\n",
       "      <td>mcbride</td>\n",
       "      <td>nassar</td>\n",
       "      <td>tyler</td>\n",
       "      <td>roger</td>\n",
       "      <td>ride</td>\n",
       "      <td>brittany</td>\n",
       "      <td>glory</td>\n",
       "      <td>spark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>live_action</td>\n",
       "      <td>dolemite</td>\n",
       "      <td>unusual</td>\n",
       "      <td>affect</td>\n",
       "      <td>moondog</td>\n",
       "      <td>toy</td>\n",
       "      <td>display</td>\n",
       "      <td>helen</td>\n",
       "      <td>hare</td>\n",
       "      <td>truth</td>\n",
       "      <td>specie</td>\n",
       "      <td>revue</td>\n",
       "      <td>diane</td>\n",
       "      <td>wallace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>national</td>\n",
       "      <td>swift</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>gay</td>\n",
       "      <td>lesson</td>\n",
       "      <td>sequel</td>\n",
       "      <td>obscure</td>\n",
       "      <td>doctor</td>\n",
       "      <td>killing</td>\n",
       "      <td>hotel</td>\n",
       "      <td>drop</td>\n",
       "      <td>orna</td>\n",
       "      <td>beanpole</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jump</td>\n",
       "      <td>troll</td>\n",
       "      <td>grim</td>\n",
       "      <td>convey</td>\n",
       "      <td>fine</td>\n",
       "      <td>marvel</td>\n",
       "      <td>purpose</td>\n",
       "      <td>slim</td>\n",
       "      <td>tower</td>\n",
       "      <td>spectacle</td>\n",
       "      <td>prince</td>\n",
       "      <td>thunder</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>information</td>\n",
       "      <td>abandon</td>\n",
       "      <td>storm</td>\n",
       "      <td>rap</td>\n",
       "      <td>survive</td>\n",
       "      <td>actually</td>\n",
       "      <td>fern</td>\n",
       "      <td>athlete</td>\n",
       "      <td>abigail</td>\n",
       "      <td>real_life</td>\n",
       "      <td>brown</td>\n",
       "      <td>bannon</td>\n",
       "      <td>eastwood</td>\n",
       "      <td>reach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrator</td>\n",
       "      <td>singe</td>\n",
       "      <td>penguin</td>\n",
       "      <td>guide</td>\n",
       "      <td>lily</td>\n",
       "      <td>stake</td>\n",
       "      <td>slow</td>\n",
       "      <td>lunch</td>\n",
       "      <td>district</td>\n",
       "      <td>zombie</td>\n",
       "      <td>cam</td>\n",
       "      <td>leroy</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>oscar_nominate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>campaign</td>\n",
       "      <td>album</td>\n",
       "      <td>ice</td>\n",
       "      <td>truck</td>\n",
       "      <td>worry</td>\n",
       "      <td>sure</td>\n",
       "      <td>split</td>\n",
       "      <td>macgowan</td>\n",
       "      <td>desperation</td>\n",
       "      <td>collective</td>\n",
       "      <td>horse</td>\n",
       "      <td>jodi</td>\n",
       "      <td>finch</td>\n",
       "      <td>palestinian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>policy</td>\n",
       "      <td>industry</td>\n",
       "      <td>bernadine</td>\n",
       "      <td>extend</td>\n",
       "      <td>connect</td>\n",
       "      <td>gloria</td>\n",
       "      <td>routine</td>\n",
       "      <td>dominic</td>\n",
       "      <td>eiffel</td>\n",
       "      <td>eve</td>\n",
       "      <td>domino</td>\n",
       "      <td>suit</td>\n",
       "      <td>naple</td>\n",
       "      <td>frank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic   #1 Topic   #2  Topic   #3 Topic   #4  Topic   #5 Topic   #6  \\\n",
       "0       danger      grace      claire        ray       exist     disney   \n",
       "1      refugee    russian    creature      third   landscape  franchise   \n",
       "2      complex     energy      dragon      emily  production    exactly   \n",
       "3  live_action   dolemite     unusual     affect     moondog        toy   \n",
       "4     national      swift  soundtrack        gay      lesson     sequel   \n",
       "5         jump      troll        grim     convey        fine     marvel   \n",
       "6  information    abandon       storm        rap     survive   actually   \n",
       "7     narrator      singe     penguin      guide        lily      stake   \n",
       "8     campaign      album         ice      truck       worry       sure   \n",
       "9       policy   industry   bernadine     extend     connect     gloria   \n",
       "\n",
       "  Topic   #7 Topic   #8   Topic   #9 Topic   #10 Topic   #11 Topic   #12  \\\n",
       "0       wake       luce       lionel         joy      simone        sean   \n",
       "1    network      tesla        shult     classic     garrone     ernesto   \n",
       "2    mcbride     nassar        tyler       roger        ride    brittany   \n",
       "3    display      helen         hare       truth      specie       revue   \n",
       "4    obscure     doctor      killing       hotel        drop        orna   \n",
       "5    purpose       slim        tower   spectacle      prince     thunder   \n",
       "6       fern    athlete      abigail   real_life       brown      bannon   \n",
       "7       slow      lunch     district      zombie         cam       leroy   \n",
       "8      split   macgowan  desperation  collective       horse        jodi   \n",
       "9    routine    dominic       eiffel         eve      domino        suit   \n",
       "\n",
       "  Topic   #13     Topic   #14  \n",
       "0    salvador           shark  \n",
       "1   almodovar        godzilla  \n",
       "2       glory           spark  \n",
       "3       diane         wallace  \n",
       "4    beanpole           sweet  \n",
       "5     kitchen           entry  \n",
       "6    eastwood           reach  \n",
       "7      lawyer  oscar_nominate  \n",
       "8       finch     palestinian  \n",
       "9       naple           frank  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_distinct_words_per_topic_df = pd.DataFrame(top_distinct_words_per_topic)\n",
    "top_distinct_words_per_topic_df = top_distinct_words_per_topic_df.transpose()\n",
    "top_distinct_words_per_topic_df.columns = [f'Topic   #{x}' for x in np.arange(1,len(top_distinct_words_per_topic)+1)]\n",
    "top_distinct_words_per_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_distinct_words_per_topic_df.to_csv(\"lda_model_outputs/top10_words_per_LDA_topic.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Top Topics For Each Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = lda_model.get_document_topics(lda_model[corpus], minimum_probability=0.0)\n",
    "all_topics_csr = gensim.matutils.corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "all_topics_df.columns = [f'Topic   #{x}' for x in np.arange(1,len(top_distinct_words_per_topic)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic   #1</th>\n",
       "      <th>Topic   #2</th>\n",
       "      <th>Topic   #3</th>\n",
       "      <th>Topic   #4</th>\n",
       "      <th>Topic   #5</th>\n",
       "      <th>Topic   #6</th>\n",
       "      <th>Topic   #7</th>\n",
       "      <th>Topic   #8</th>\n",
       "      <th>Topic   #9</th>\n",
       "      <th>Topic   #10</th>\n",
       "      <th>Topic   #11</th>\n",
       "      <th>Topic   #12</th>\n",
       "      <th>Topic   #13</th>\n",
       "      <th>Topic   #14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.081347</td>\n",
       "      <td>0.063319</td>\n",
       "      <td>0.550680</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.034330</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.017925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.081795</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>0.052709</td>\n",
       "      <td>0.044891</td>\n",
       "      <td>0.039092</td>\n",
       "      <td>0.529063</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>0.025775</td>\n",
       "      <td>0.023752</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.020529</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.081019</td>\n",
       "      <td>0.561970</td>\n",
       "      <td>0.052306</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.038772</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>0.030811</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.017928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>0.288821</td>\n",
       "      <td>0.063872</td>\n",
       "      <td>0.052502</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>0.038902</td>\n",
       "      <td>0.323527</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.021915</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.579746</td>\n",
       "      <td>0.063455</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.038749</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.017917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic   #1  Topic   #2  Topic   #3  Topic   #4  Topic   #5  Topic   #6  \\\n",
       "562     0.081347    0.063319    0.550680    0.044518    0.038765    0.034330   \n",
       "679     0.081795    0.063827    0.052709    0.044891    0.039092    0.529063   \n",
       "312     0.081019    0.561970    0.052306    0.044527    0.038772    0.034336   \n",
       "1550    0.288821    0.063872    0.052502    0.044680    0.038902    0.323527   \n",
       "622     0.579746    0.063455    0.052278    0.044504    0.038749    0.034314   \n",
       "\n",
       "      Topic   #7  Topic   #8  Topic   #9  Topic   #10  Topic   #11  \\\n",
       "562     0.030806    0.027938    0.025559     0.023553     0.021839   \n",
       "679     0.031066    0.028174    0.025775     0.023752     0.022023   \n",
       "312     0.030811    0.027943    0.025563     0.023557     0.021842   \n",
       "1550    0.030914    0.028036    0.025648     0.023635     0.021915   \n",
       "622     0.030792    0.027925    0.025547     0.023542     0.021829   \n",
       "\n",
       "      Topic   #12  Topic   #13  Topic   #14  \n",
       "562      0.020357     0.019064     0.017925  \n",
       "679      0.020529     0.019225     0.018077  \n",
       "312      0.020361     0.019067     0.017928  \n",
       "1550     0.020429     0.019131     0.017988  \n",
       "622      0.020348     0.019055     0.017917  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join NYT Reviews with Associated Topic Relatedness Values\n",
    "NYTReviews.join(all_topics_df,how=\"left\").to_csv(\"lda_model_outputs/NYT_Reviews_w_TopicRelatedness.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Topic Based On Topic with Highest Probability for Each Review:\n",
    "all_topics_df['Topic_Assignment'] = all_topics_df[list(all_topics_df.columns[:])].idxmax(axis=1)\n",
    "NYTReviews.join(all_topics_df[['Topic_Assignment']],how=\"left\").to_csv(\"lda_model_outputs/NYT_Reviews_w_TopicAssignment.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0d4e572fc01779b683641842e5699b5364ec3fd8789377319514354924fc870"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('SIADS694': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
